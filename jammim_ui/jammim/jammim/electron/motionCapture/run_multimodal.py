import torch
import whisper
import os
from openai import OpenAI
from encoder import SLIPVideoEncoder 
from models import HybridTemporalModel
import sys # sys.stderr ì¶œë ¥ì„ ìœ„í•´ import
import numpy as np # ğŸ‘ˆ numpy.ndarray íƒ€ì…ì„ ì‚¬ìš©í–ˆìœ¼ë¯€ë¡œ ì¶”ê°€í•©ë‹ˆë‹¤.

# âš ï¸ API í‚¤ íŒŒì¼ì„ ì½ëŠ” í•¨ìˆ˜ ì •ì˜
def load_openai_api_key(filepath="openai.txt"):
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            # íŒŒì¼ì˜ ì²« ë²ˆì§¸ ì¤„ì„ í‚¤ë¡œ ì‚¬ìš© (ì¤„ë°”ê¿ˆ ì œê±°)
            key = f.readline().strip()
            if not key:
                raise ValueError("API í‚¤ íŒŒì¼ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
            return key
    except FileNotFoundError:
        print(f"âŒ ì˜¤ë¥˜: API í‚¤ íŒŒì¼ '{filepath}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", file=sys.stderr)
        raise
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: API í‚¤ íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", file=sys.stderr)
        raise
        
def print_error(message):
    """ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ sys.stderrë¡œ ì¶œë ¥í•˜ì—¬ Electron ì½˜ì†”ì— í‘œì‹œí•©ë‹ˆë‹¤."""
    print(message, file=sys.stderr)


class MultimodalAgent:
    def __init__(self, model_path, proto_path, device="cuda"):
        self.device = device
        
        # 1. ìˆ˜ì–´ ëª¨ë¸ ë¡œë“œ
        self.encoder = SLIPVideoEncoder(pretrained=False, embed_dim=512).to(device)
        self.temporal = HybridTemporalModel(input_dim=512, hidden_dim=512).to(device)
        
        try:
            checkpoint = torch.load(model_path, map_location=device)
            self.encoder.load_state_dict(checkpoint['encoder'])
            self.temporal.load_state_dict(checkpoint['temporal'])
        except FileNotFoundError:
            print_error(f"âŒ ì˜¤ë¥˜: ëª¨ë¸ íŒŒì¼ '{model_path}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            raise
        self.encoder.eval()
        self.temporal.eval()

        # 2. í”„ë¡œí† íƒ€ì…(ê¸°ì¤€ì ) ë¡œë“œ
        print_error("ğŸ“‚ ìˆ˜ì–´ ê¸°ì¤€ì (Prototype) ë¡œë”© ì¤‘...")
        try:
            # self.prototypesëŠ” ë¡œë“œëœ ë”•ì…”ë„ˆë¦¬ ì „ì²´
            data = torch.load(proto_path, map_location=device) 
        except FileNotFoundError:
            print_error(f"âŒ ì˜¤ë¥˜: í”„ë¡œí† íƒ€ì… íŒŒì¼ '{proto_path}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. make_prototypes.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
            raise
        
        # ğŸš¨ğŸš¨ ìˆ˜ì •ëœ ë¶€ë¶„: ë¡œë“œëœ ë”•ì…”ë„ˆë¦¬ êµ¬ì¡°ì— ë”°ë¼ í´ë˜ìŠ¤ ì´ë¦„ê³¼ í”„ë¡œí† íƒ€ì… ì¶”ì¶œ ğŸš¨ğŸš¨
        
        # 1) ë§Œì•½ íŒŒì¼ì´ {'classes': [ì´ë¦„ë“¤], 'prototypes': Tensor} êµ¬ì¡°ë¼ë©´:
        if isinstance(data, dict) and 'classes' in data and 'prototypes' in data:
            self.class_names = data['classes']
            self.proto_matrix = data['prototypes'].to(device)
            
            if not isinstance(self.proto_matrix, torch.Tensor):
                raise TypeError("ë¡œë”©ëœ 'prototypes' í‚¤ì˜ ê°’ì´ Tensorê°€ ì•„ë‹™ë‹ˆë‹¤.")
        
        # 2) ë§Œì•½ íŒŒì¼ì´ {í´ë˜ìŠ¤ì´ë¦„: í…ì„œ, í´ë˜ìŠ¤ì´ë¦„2: í…ì„œ, ...} í˜•íƒœë¼ë©´:
        else:
            self.prototypes = data # ë”•ì…”ë„ˆë¦¬ {ì´ë¦„: í…ì„œ}
            self.class_names = []
            proto_tensors = []
            
            for key, value in self.prototypes.items():
                # í…ì„œë‚˜ NumPy ë°°ì—´ë§Œ í•„í„°ë§í•˜ê³  ë¬¸ìì—´(str) ê°™ì€ ê²ƒì€ ë¬´ì‹œ
                if isinstance(value, torch.Tensor) or isinstance(value, np.ndarray):
                    self.class_names.append(key)
                    # í…ì„œê°€ ì•„ë‹ˆë©´ (NumPy ë°°ì—´ì´ë©´) ê°•ì œ ë³€í™˜
                    if not isinstance(value, torch.Tensor):
                        value = torch.tensor(value, dtype=torch.float32)
                    proto_tensors.append(value)
                else:
                    # 'str' ê°™ì€ ë¶ˆìˆœë¬¼ì€ ê²½ê³ ë§Œ ì¶œë ¥í•˜ê³  ê±´ë„ˆëœë‹ˆë‹¤.
                    print_error(f"âš ï¸ ê²½ê³ : í”„ë¡œí† íƒ€ì… ë”•ì…”ë„ˆë¦¬ì—ì„œ ì˜ˆìƒì¹˜ ëª»í•œ ê°’({key}: {type(value)})ì´ ë°œê²¬ë˜ì–´ ë¬´ì‹œí•©ë‹ˆë‹¤.")

            if not proto_tensors:
                 raise ValueError("í”„ë¡œí† íƒ€ì… ë”•ì…”ë„ˆë¦¬ì—ì„œ ìœ íš¨í•œ í…ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                 
            self.proto_matrix = torch.stack(proto_tensors).to(device)
            
        # -----------------------------------------------------------------------

        # 3. Whisper ë¡œë“œ
        print_error("ğŸ§ Whisper ëª¨ë¸ ë¡œë“œ ì¤‘...")
        try:
            self.whisper = whisper.load_model("base").to(device)
        except Exception as e:
            print_error(f"âŒ ì˜¤ë¥˜: Whisper ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨. ì—ëŸ¬: {e}")
            raise

        # 4. LLM í´ë¼ì´ì–¸íŠ¸ (OpenAI ì˜ˆì‹œ)
        # ğŸŒŸğŸŒŸğŸŒŸ ìˆ˜ì •ëœ ë¶€ë¶„: íŒŒì¼ì—ì„œ API í‚¤ ë¡œë“œ ğŸŒŸğŸŒŸğŸŒŸ
        try:
            api_key = load_openai_api_key()
            self.client = OpenAI(api_key=api_key) 
        except Exception as e:
            print_error(f"âŒ ì˜¤ë¥˜: OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨. 'openai.txt' íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”. ì—ëŸ¬: {e}")
            raise

    def predict_sign(self, video_tensor):
        """ì €ì¥ëœ í”„ë¡œí† íƒ€ì…ê³¼ ë¹„êµí•˜ì—¬ ê°€ì¥ ê°€ê¹Œìš´ ìˆ˜ì–´ ë‹¨ì–´ ì°¾ê¸°"""
        with torch.no_grad():
            video_tensor = video_tensor.to(self.device)
            features = self.encoder(video_tensor)
            query_emb = self.temporal(features) # (1, 512)

            # ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê³„ì‚° (Euclidean Distance)
            dists = torch.cdist(query_emb, self.proto_matrix) # (1, Class_Num)
            
            # ê°€ì¥ ê±°ë¦¬ê°€ ì§§ì€ ì¸ë±ìŠ¤ ì°¾ê¸°
            min_dist_idx = torch.argmin(dists, dim=1).item()
            predicted_word = self.class_names[min_dist_idx]
            
            return predicted_word

    def generate_response(self, video_tensor, audio_path):
        # 1. ì¸ì‹ ìˆ˜í–‰
        sign_word = self.predict_sign(video_tensor)
        
        try:
            audio_result = self.whisper.transcribe(audio_path)['text']
        except Exception as e:
            print_error(f"âŒ ì˜¤ë¥˜: Whisper ìŒì„± ì¸ì‹ ì‹¤íŒ¨. ì—ëŸ¬: {e}")
            audio_result = "[ìŒì„± ì¸ì‹ ì‹¤íŒ¨]"
            
        print_error(f"\nğŸ‘€ ìˆ˜ì–´ ì¸ì‹: {sign_word}")
        print_error(f"ğŸ‘‚ ìŒì„± ì¸ì‹: {audio_result}")

        # 2. LLM í”„ë¡¬í”„íŠ¸ (Prompt Engineering)
        system_prompt = "ë‹¹ì‹ ì€ ì²­ê° ì¥ì• ì¸ê³¼ ë¹„ì¥ì• ì¸ì˜ ì†Œí†µì„ ë•ëŠ” í†µì—­ì‚¬ì…ë‹ˆë‹¤. ìˆ˜ì–´ ë‹¨ì–´ì™€ ìŒì„± í…ìŠ¤íŠ¸ê°€ ì£¼ì–´ì§€ë©´, ë¬¸ë§¥ì„ ê³ ë ¤í•˜ì—¬ ì‚¬ìš©ìì˜ ì˜ë„ë¥¼ ì™„ë²½í•œ í•œêµ­ì–´ ë¬¸ì¥ìœ¼ë¡œ ë§Œë“œì„¸ìš”."
        
        user_prompt = f"""
        [ì…ë ¥ ì •ë³´]
        ìˆ˜ì–´ ë‹¨ì–´: {sign_word}
        ìŒì„± í…ìŠ¤íŠ¸: {audio_result}

        [ì§€ì‹œ ì‚¬í•­]
        1. ìˆ˜ì–´ ë‹¨ì–´ëŠ” í•µì‹¬ í‚¤ì›Œë“œì…ë‹ˆë‹¤.
        2. ìŒì„± í…ìŠ¤íŠ¸ê°€ ë¶ˆì™„ì „í•˜ê±°ë‚˜ ì§§ìœ¼ë©´ ìˆ˜ì–´ ë‹¨ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‚´ìš©ì„ ë³´ì™„í•˜ì„¸ìš”.
        3. ë°˜ëŒ€ë¡œ ìˆ˜ì–´ ë‹¨ì–´ë§Œìœ¼ë¡œ ë¶€ì¡±í•˜ë©´ ìŒì„±ì„ ì°¸ê³ í•˜ì„¸ìš”.
        4. ê²°ê³¼ëŠ” 'í•´ì„ëœ ë¬¸ì¥' ë”± í•˜ë‚˜ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
        5. ì‚¬ìš©ìê°€ ì–´ë–¤ ë°©í–¥ì„ ê°€ë¦¬í‚¤ê³  ìˆëŠ”ì§€ (ì˜ˆ: 'ì™¼ìª½', 'ì˜¤ë¥¸ìª½', 'ìœ„', 'ì•„ë˜') ìŒì„±ì´ë‚˜ ìˆ˜ì–´ ë§¥ë½ì„ ë°”íƒ•ìœ¼ë¡œ ì¶”ë¡ í•˜ê³  í•´ì„ ë¬¸ì¥ì— í¬í•¨í•˜ì„¸ìš”.

        [ì˜ˆì‹œ 1]
        ìˆ˜ì–´: ë°°ê³ íŒŒ / ìŒì„±: ì—„ë§ˆ ë°¥
        í•´ì„: ì—„ë§ˆ, ì € ë°°ê³ íŒŒìš”. ë°¥ ì£¼ì„¸ìš”.

        [ì˜ˆì‹œ 2]
        ìˆ˜ì–´: ë³‘ì› / ìŒì„±: ë¨¸ë¦¬ê°€ ë„ˆë¬´ ì•„íŒŒ
        í•´ì„: ë¨¸ë¦¬ê°€ ë„ˆë¬´ ì•„íŒŒì„œ ë³‘ì›ì— ê°€ê³  ì‹¶ì–´ìš”.

        [ì‹¤ì œ ë¬¸ì œ]
        ìˆ˜ì–´: {sign_word} / ìŒì„±: {audio_result}
        í•´ì„:
        """

        # 3. LLM í˜¸ì¶œ
        try:
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo", # ë˜ëŠ” ë‹¤ë¥¸ ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.7
            )
            return response.choices[0].message.content
        except Exception as e:
            print_error(f"âŒ ì˜¤ë¥˜: LLM API í˜¸ì¶œ ì‹¤íŒ¨. API í‚¤ ë˜ëŠ” ì¸í„°ë„· ì—°ê²° í™•ì¸ í•„ìš”. ì—ëŸ¬: {e}")
            return "âŒ LLM í˜¸ì¶œ ì‹¤íŒ¨ (API ì˜¤ë¥˜)"


def main_run(model_path, proto_path, video_file, audio_file):
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    print_error(f"ğŸš€ ë©€í‹°ëª¨ë‹¬ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì¤‘... (Device: {device})")
    try:
        agent = MultimodalAgent(model_path, proto_path, device)
    except Exception as e:
        # ğŸš¨ ìˆ˜ì •: êµ¬ì²´ì ì¸ ì˜¤ë¥˜ ë©”ì‹œì§€(e)ë¥¼ ì¶œë ¥í•˜ë„ë¡ ë³€ê²½
        print_error(f"âŒ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨ë¡œ ì¢…ë£Œí•©ë‹ˆë‹¤. ìƒì„¸ ì˜¤ë¥˜: {e}")
        return

    # 1. ë¹„ë””ì˜¤ í…ì„œ ë¡œë“œ
    print_error(f"ğŸ“‚ ë¹„ë””ì˜¤ í…ì„œ ë¡œë”© ì¤‘: {video_file}")
    try:
        video_tensor = torch.load(video_file, map_location=device).float()
    except Exception as e:
        print_error(f"âŒ ë¹„ë””ì˜¤ í…ì„œ ë¡œë“œ ì‹¤íŒ¨. íŒŒì¼ì´ ì†ìƒë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—ëŸ¬: {e}")
        return
    
    # ğŸš¨ğŸš¨ ìˆ˜ì •: [T, C, H, W] í˜•íƒœë¥¼ [1, C, T, H, W] í˜•íƒœë¡œ ë³€í™˜ (Cì™€ T ìœ„ì¹˜ ë³€ê²½)
    if video_tensor.dim() == 4:
        # í˜„ì¬ í˜•íƒœê°€ (T, C, H, W)ë¼ë©´ -> (C, T, H, W)ë¡œ permute
        # ìº¡ì²˜ëœ í…ì„œì˜ ì°¨ì›ì´ (89, 3, 224, 224)ë¼ê³  ê°€ì •
        if video_tensor.size(1) == 3:
             # í˜•íƒœê°€ ì´ë¯¸ (T, C, H, W)ë¼ë©´, Cì™€ Të¥¼ ë°”ê¿” (C, T, H, W)ë¡œ ë§Œë“­ë‹ˆë‹¤.
             video_tensor = video_tensor.permute(1, 0, 2, 3) 
        
        # ìµœì¢…ì ìœ¼ë¡œ Batch ì°¨ì› (1)ì„ ì¶”ê°€í•˜ì—¬ (1, C, T, H, W)ë¡œ ë§Œë“­ë‹ˆë‹¤.
        video_tensor = video_tensor.unsqueeze(0) 

    # 2. ë©€í‹°ëª¨ë‹¬ ì¶”ë¡  ë° ì‘ë‹µ ìƒì„±
    print_error("ğŸ§  LLM ì‘ë‹µ ìƒì„± ì‹œì‘...")
    
    llm_response = agent.generate_response(video_tensor, audio_file)
    
    if "âŒ LLM í˜¸ì¶œ ì‹¤íŒ¨" not in llm_response:
        print(llm_response.strip()) # ğŸ‘ˆ ìµœì¢… ê²°ê³¼ëŠ” stdoutìœ¼ë¡œ ì¶œë ¥ë©ë‹ˆë‹¤.
    else:
        print_error("âŒ ìµœì¢… ì¶œë ¥ ì‹¤íŒ¨.")
        
    print_error("="*50 + "\n")


if __name__ == '__main__':
    # âš ï¸ ìº¡ì²˜ íŒŒì¼ ê²½ë¡œê°€ motionCapture.pyì™€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
    MODEL_PATH = "slip_protonet_final.pth" 
    PROTO_PATH = "prototypes.pt"
    VIDEO_FILE = "captured_video.pt" 
    AUDIO_FILE = "captured_audio.wav"
    
    if os.path.exists(VIDEO_FILE) and os.path.exists(AUDIO_FILE):
        main_run(MODEL_PATH, PROTO_PATH, VIDEO_FILE, AUDIO_FILE)
    else:
        print_error(f"âš ï¸ {VIDEO_FILE} ë˜ëŠ” {AUDIO_FILE} íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        print_error("motionCapture.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ ìˆ˜ì–´ ë™ì‘ê³¼ ìŒì„±ì„ ìº¡ì²˜í•´ì£¼ì„¸ìš”.")